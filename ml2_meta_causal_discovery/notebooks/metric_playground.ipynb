{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "# Define metrics functions based on your provided code\n",
    "def expected_f1_score(target, pred, check_acyclic=False):\n",
    "    f1_all = np.zeros(pred.shape[1])\n",
    "    for i in range(pred.shape[1]):\n",
    "        curr_pred = pred[:, i]\n",
    "        curr_target = target[i]\n",
    "        f1_sample = []\n",
    "        for j in range(curr_pred.shape[0]):\n",
    "            curr_sample_pred = curr_pred[j]\n",
    "            f1 = f1_score(\n",
    "                curr_target.flatten(),\n",
    "                curr_sample_pred.flatten(),\n",
    "                average=\"binary\",\n",
    "                zero_division=0,\n",
    "            )\n",
    "            f1_sample.append(f1)\n",
    "        f1_all[i] = np.mean(f1_sample)\n",
    "    return f1_all\n",
    "\n",
    "def log_prob_graph_scores(targets, preds):\n",
    "    all_log_probs = []\n",
    "    for batch_idx in range(targets.shape[0]):\n",
    "        sample_mean = th.mean(preds[:, batch_idx], axis=0)\n",
    "        sample_mean_flatten = sample_mean.flatten()\n",
    "        current_batch = targets[batch_idx]\n",
    "        current_batch_flatten = current_batch.flatten()\n",
    "\n",
    "        bern_dist = th.distributions.bernoulli.Bernoulli(probs=sample_mean_flatten)\n",
    "        log_prob = bern_dist.log_prob(current_batch_flatten).sum()\n",
    "        all_log_probs.append(log_prob.cpu().item())\n",
    "    return all_log_probs\n",
    "\n",
    "def auc_graph_scores(targets, preds):\n",
    "    if isinstance(targets, th.Tensor):\n",
    "        targets = targets.cpu().numpy()\n",
    "    if isinstance(preds, th.Tensor):\n",
    "        preds = preds.cpu().numpy()\n",
    "\n",
    "    all_aucs = []\n",
    "    for batch_idx in range(targets.shape[0]):\n",
    "        sample_mean = np.mean(preds[:, batch_idx], axis=0)\n",
    "        sample_mean_flatten = sample_mean.flatten()\n",
    "        current_batch = targets[batch_idx]\n",
    "        current_batch_flatten = current_batch.flatten()\n",
    "        auc = roc_auc_score(current_batch_flatten, sample_mean_flatten, average=\"macro\")\n",
    "        all_aucs.append(auc)\n",
    "    return all_aucs\n",
    "\n",
    "# Generate 50% [[0, 1], [0, 0]] and 50% [[0, 0], [1, 0]] for 100 batches\n",
    "batch_size = 100\n",
    "target_1 = np.array([[0, 1], [0, 0]])\n",
    "target_2 = np.array([[0, 0], [1, 0]])\n",
    "targets = np.array([target_1 if i % 2 == 0 else target_2 for i in range(batch_size)])\n",
    "\n",
    "# Generate samples from Bernoulli[[0, 0.5], [0.5, 0]]\n",
    "preds_bernoulli_probs = np.array([[0, 0.5], [0.5, 0]])\n",
    "num_samples = 500\n",
    "preds = np.random.binomial(n=1, p=preds_bernoulli_probs, size=(num_samples, batch_size, 2, 2))\n",
    "\n",
    "# Convert targets and preds to torch tensors\n",
    "targets_th = th.tensor(targets, dtype=th.float32)\n",
    "preds_th = th.tensor(preds, dtype=th.float32)\n",
    "\n",
    "# Evaluate the metrics\n",
    "expected_f1 = expected_f1_score(targets, preds)\n",
    "log_probs = log_prob_graph_scores(targets_th, preds_th)\n",
    "auc_scores = auc_graph_scores(targets_th, preds_th)\n",
    "\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Metrics Evaluation\", dataframe={\n",
    "    \"Expected F1\": expected_f1,\n",
    "    \"Log Probability\": log_probs,\n",
    "    \"AUC Scores\": auc_scores\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "np_causal_discovery_3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
